# class-imbalance-effects1

This project simulates a classification problem with two groups (A and B) to analyze the effect of class imbalance on model performance using a sliding window approach. It generates a dataset with 50 features, introducing subtle mean differences between the groups. The train and test set sizes for Group A gradually decrease, while those for Group B increase. Three classification models—Random Forest, XGBoost, and Logistic Regression—are trained and evaluated. Each configuration undergoes multiple iterations, and results are averaged to ensure robustness. Performance metrics such as accuracy, precision, recall, AUC, and confusion matrices are computed. Finally, the summarized results are visualized to provide insights into model behavior under different class imbalance scenarios. Running the script allows users to train and evaluate models across varying train-test configurations.
